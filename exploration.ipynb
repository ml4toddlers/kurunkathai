{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "import transformers \n",
    "import torch\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipeline = transformers.pipeline(\"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\",return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['வணக்கம், நீங்கள் எப்படி இருக்கிறீர்கள்?', 'நான் நன்றாக இருக்கிறேன், நன்றி.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "translator = GoogleTranslator(source='en', target='ta')\n",
    "translator.translate_batch(batch=[\"Hello, how are you?\", \"I am fine, thank you.\"], src=\"en\", dest=\"ta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"ta_tinystories_google_translate\")\n",
    "len( ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_indices(ds, split, start_index, num_batches, batch_size=500, odir=\"chunks\"):\n",
    "    end_index = start_index + num_batches * batch_size\n",
    "    translator = GoogleTranslator(source='en', target='ta')\n",
    "    translated_sublist = []\n",
    "    for i in range(start_index, end_index, batch_size):\n",
    "        batch =  ds[split][i:i+batch_size][\"text\"]\n",
    "        translated = translator.translate_batch(batch=batch)\n",
    "        translated_sublist.extend([ {idx+start_index:item} for idx,item in enumerate(translated)])\n",
    "    with open(f\"{odir}/{split}_{start_index}_{end_index}.json\", \"w\") as f:\n",
    "        json.dump(translated_sublist, f)\n",
    "    return translated_sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeep_translator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleTranslator\n\u001b[0;32m----> 2\u001b[0m ta_ls\u001b[38;5;241m=\u001b[39m\u001b[43mtranslate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_en\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36mtranslate_indices\u001b[0;34m(ds, split, start_index, num_batches, batch_size, odir)\u001b[0m\n\u001b[1;32m      8\u001b[0m     translated_sublist\u001b[38;5;241m.\u001b[39mextend([ {idx\u001b[38;5;241m+\u001b[39mstart_index:item} \u001b[38;5;28;01mfor\u001b[39;00m idx,item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(translated)])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00modir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(translated_sublist, f)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m translated_sublist\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "ta_ls=translate_indices(ds_en,\"train\",0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"chunks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from googletrans import Translator\n",
    "async def translate_bulk(inputs):\n",
    "    translator = Translator()\n",
    "    loop = asyncio.get_running_loop()\n",
    "\n",
    "    # Run translate() in an executor to avoid blocking\n",
    "    translations = await loop.run_in_executor(None, translator.translate, inputs, 'ta')\n",
    "\n",
    "    # Ensure translations is always a list\n",
    "    if not isinstance(translations, list):\n",
    "        translations = [translations]\n",
    "\n",
    "    for translation in translations:\n",
    "        print(translation.origin, ' -> ', translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "def collate_text(batch):\n",
    "    return [item[\"text\"] for item in batch]\n",
    "ds_en = load_dataset(\"roneneldan/TinyStories\")\n",
    "dataloader = DataLoader(ds[\"train\"], batch_size = 500, shuffle = False, collate_fn = collate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loader =(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_SingleProcessDataLoaderIter' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43miter_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_SingleProcessDataLoaderIter' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "iter_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "translator = GoogleTranslator(source='en', target='ta')\n",
    "translations = translator.translate_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ஒரு நாள், லில்லி என்ற சிறுமி தனது அறையில் ஒரு ஊசியைக் கண்டாள். அது கூர்மையாக இருந்ததால் அதனுடன் விளையாடுவது கடினம் என்று அவளுக்குத் தெரியும். லில்லி தனது அம்மாவுடன் ஊசியைப் பகிர்ந்து கொள்ள விரும்பினார், அதனால் அவள் சட்டையில் ஒரு பொத்தானை தைக்க முடியும்.\\n\\nலில்லி தனது அம்மாவிடம் சென்று, \"அம்மா, நான் இந்த ஊசியைக் கண்டேன். நீங்கள் அதை என்னுடன் பகிர்ந்து கொண்டு என் சட்டையை தைக்க முடியுமா?\" அவளுடைய அம்மா புன்னகைத்து, \"ஆம், லில்லி, நாங்கள் ஊசியைப் பகிர்ந்துகொண்டு உங்கள் சட்டையை சரிசெய்யலாம்\" என்றார்.\\n\\nஒன்றாக, அவர்கள் ஊசியைப் பகிர்ந்துகொண்டு லில்லி சட்டையில் பொத்தானை தைத்தனர். அவர்கள் ஒருவருக்கொருவர் பகிர்ந்துகொண்டு உதவுவதால் அவர்களுக்கு இது கடினம் அல்ல. அவர்கள் முடிந்ததும், ஊசியைப் பகிர்ந்துகொண்டு தனது சட்டையை சரிசெய்ததற்காக லில்லி தனது அம்மாவுக்கு நன்றி தெரிவித்தார். அவர்கள் இருவரும் மகிழ்ச்சியாக உணர்ந்தார்கள், ஏனெனில் அவர்கள் பகிர்ந்து கொண்டனர் மற்றும் ஒன்றாக வேலை செய்தனர்.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ds[\"train\"][i][\"text\"] for i in range(1000)]\n",
    "async def main():\n",
    "    await translate_bulk(inputs)\n",
    "asyncio.create_task(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a translator. I will tell you a story in words that a 4 year old can understand. You will translate it to Tamil for me\"\n",
    "message = ds[\"train\"][-1][\"text\"]\n",
    "final_input = [\n",
    "    {\"role\": \"assistant\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": message}\n",
    "]\n",
    "print(final_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='gemma2', messages=final_input)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"abhinand/tamil-llama-7b-instruct-v0.2\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe(final_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ஒருநாள், ஒரு சிறுமி சிலி (Lily) இன் அறையில் ஒரு துளையினை கண்டார். அவள் அது விளையாட முடியாது என்பதனாலும், அது கூரானதாக இருப்பதால் மட்டும் தெரிந்திருந்தது. சிலி அவளை தாய்விடம் பகிர்ந்து கொள்ள விரும்பினார், அ\n",
    "அதனால் அவர் துணிகளில் ஒரு பட்டனை இணைக்கலாம். சிலி தாயாரிடம் சென்று \"அம்மா, நான் ஒரு துளையினை கண்டேன். நீங்கள் எனது உடையில் ஒரு பட்டனை இணைக்க போதும்.\" என்று கூறினார். அம்மா சிரித்துப் பேசினார்: \"ஆம் சிலி, ந\n",
    "நாங்கள் துளையைப் பகிர்ந்து கொண்டு உன் உடையின் பட்டனை இணைக்கலாம்.\"\n",
    "\n",
    "இருவரும் துளையினைப் பகிர்ந்து கொண்டு உடையில் பட்டனை இணைத்தார்கள். அது அவர்களுக்கு கடினமில்லை, ஏனென்றால் அவர்கள் ஒன்றுக்கொன்று உதவி செய்து கொண்டார்கள். முடிந்தவுடன் சிலி தாயாருக்கு துளையினைப் பகிர்ந்து கொ\n",
    "கொடுத்தது மட்டுமல்லாமல், உடையின் பட்டனை இணைத்ததற்காகவும் நன்றி தெரிவித்தார். இருவரும் சேர்ந்து பணி செய்ததால் அந்த நிமிடம் மிகவும் மகிழ்ச்சியானதாக இருந்தது.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe2 = pipeline(\"text-generation\", model=\"roneneldan/TinyStories-8M\")\n",
    "print(pipe2(\"Once upon a time in a cave on top of a hill\", max_new_tokens=400)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe3 = pipeline(\"text-generation\", model=\"roneneldan/TinyStories-33M\")\n",
    "print(pipe3(\"Once upon a time in a cave on top of a hill\", max_new_tokens=400)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-135M\", device_map=\"auto\")\n",
    "print(pipe(\"Once upon a time in a cave on top of a hill\", max_new_tokens=400)[0][\"generated_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
